service: jedeschule

frameworkVersion: '4'

provider:
  name: aws
  region: eu-central-1
  runtime: python3.10
  environment:
    FEED_BUCKET_NAME: !Ref ScraperFeedBucket
  iam:
    role:
      statements:
      - Effect: "Allow"
        Action:
          - "s3:PutObject"
        Resource: !Sub
          - "arn:aws:s3:::#{BucketName}/*"
          - BucketName: !Ref ScraperFeedBucket

resources:
  - AWSTemplateFormatVersion: "2010-09-09"
    Transform: "AWS::Serverless-2016-10-31"
  - ${file(./s3-template.yml)}

functions:
  hello:
    handler: handler.hello
  lambdaScrape:
    handler: launcher.scrape
    timeout: 900  # 15 minutes, for long-running spiders
    events:
      - schedule:
          name: Scrape_Baden-Wuerttemberg
          rate: cron(0 1 * * ? *)  # 01:00
          input:
            spider_name: "baden-wuerttemberg"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Bayern
          rate: cron(0 2 * * ? *)  # 02:00
          input:
            spider_name: "bayern"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Berlin
          rate: cron(0 3 * * ? *)  # 03:00
          input:
            spider_name: "berlin"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Brandenburg
          rate: cron(0 4 * * ? *)  # 04:00
          input:
            spider_name: "brandenburg"
            settings:
              LOG_LEVEL: "INFO"
        spider_name: "brandenburg"
        settings:
          LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Bremen
          rate: cron(0 5 * * ? *)  # 05:00
          input:
            spider_name: "bremen"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Hamburg
          rate: cron(0 6 * * ? *)  # 06:00
          input:
            spider_name: "hamburg"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Hessen
          rate: cron(0 7 * * ? *)  # 07:00
          input:
            spider_name: "hessen"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Nordrhein-Westfalen
          rate: cron(0 12 * * ? *)  # 12:00
          input:
            spider_name: "nordrhein-westfalen"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Sachsen-Anhalt
          rate: cron(0 14 * * ? *)  # 14:00
          input:
            spider_name: "sachsen-anhalt"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Schleswig-Holstein
          rate: cron(0 15 * * ? *)  # 15:00
          input:
            spider_name: "schleswig-holstein"
            settings:
              LOG_LEVEL: "INFO"
      - schedule:
          name: Scrape_Thueringen
          rate: cron(0 16 * * ? *)  # 16:00
          input:
            spider_name: "thueringen"
            settings:
              LOG_LEVEL: "INFO"


# We include files by whitelisting to reduce the deployment time.
# Just remember to add any files you create!
package:
  include:
    - launcher.py
    - jedeschule/**
    - scrapy.cfg
  exclude:
    - "./**"

plugins:
  - serverless-python-requirements
  - serverless-cloudformation-sub-variables
custom:
  pythonRequirements:
    slim: true # Omits tests, __pycache__, *.pyc etc from dependencies
    fileName: requirements.txt
